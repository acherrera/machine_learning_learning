{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "tutorial-steam",
   "metadata": {},
   "source": [
    "Sounds kind of basic, but if you can't save and load the model, than what is the point in even training it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "quiet-realtor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -q pyyaml h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "urban-toolbox",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "print(tf.version.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "hidden-abortion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the MNIST dataset and only the first 1000 sample to make it faster\n",
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "train_labels = train_labels[:1000]\n",
    "test_labels = test_labels[:1000]\n",
    "\n",
    "train_images = train_images[:1000].reshape(-1, 28 * 28) / 255.0\n",
    "test_images = test_images[:1000].reshape(-1, 28 * 28) / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "unlikely-pursuit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define a simple sequential model\n",
    "def create_model():\n",
    "    model = tf.keras.models.Sequential([\n",
    "        keras.layers.Dense(512, activation='relu', input_shape=(784,)),\n",
    "        keras.layers.Dropout(0.2),\n",
    "        keras.layers.Dense(10)\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "              loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=[tf.metrics.SparseCategoricalAccuracy()])\n",
    "    return model\n",
    "\n",
    "# Create a basic model instance\n",
    "model = create_model()\n",
    "\n",
    "# Display the model's architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "coupled-memory",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "32/32 [==============================] - 2s 43ms/step - loss: 1.6072 - sparse_categorical_accuracy: 0.5131 - val_loss: 0.7504 - val_sparse_categorical_accuracy: 0.7710\n",
      "\n",
      "Epoch 00001: saving model to training_1\\cp.ckpt\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.4749 - sparse_categorical_accuracy: 0.8620 - val_loss: 0.5407 - val_sparse_categorical_accuracy: 0.8380\n",
      "\n",
      "Epoch 00002: saving model to training_1\\cp.ckpt\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.2869 - sparse_categorical_accuracy: 0.9368 - val_loss: 0.5014 - val_sparse_categorical_accuracy: 0.8430\n",
      "\n",
      "Epoch 00003: saving model to training_1\\cp.ckpt\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.2152 - sparse_categorical_accuracy: 0.9435 - val_loss: 0.4799 - val_sparse_categorical_accuracy: 0.8500\n",
      "\n",
      "Epoch 00004: saving model to training_1\\cp.ckpt\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1664 - sparse_categorical_accuracy: 0.9636 - val_loss: 0.4405 - val_sparse_categorical_accuracy: 0.8610\n",
      "\n",
      "Epoch 00005: saving model to training_1\\cp.ckpt\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.1315 - sparse_categorical_accuracy: 0.9718 - val_loss: 0.4310 - val_sparse_categorical_accuracy: 0.8630\n",
      "\n",
      "Epoch 00006: saving model to training_1\\cp.ckpt\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0823 - sparse_categorical_accuracy: 0.9856 - val_loss: 0.4310 - val_sparse_categorical_accuracy: 0.8580\n",
      "\n",
      "Epoch 00007: saving model to training_1\\cp.ckpt\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0668 - sparse_categorical_accuracy: 0.9940 - val_loss: 0.4061 - val_sparse_categorical_accuracy: 0.8710\n",
      "\n",
      "Epoch 00008: saving model to training_1\\cp.ckpt\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0508 - sparse_categorical_accuracy: 0.9988 - val_loss: 0.3967 - val_sparse_categorical_accuracy: 0.8710\n",
      "\n",
      "Epoch 00009: saving model to training_1\\cp.ckpt\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0408 - sparse_categorical_accuracy: 0.9954 - val_loss: 0.4258 - val_sparse_categorical_accuracy: 0.8660\n",
      "\n",
      "Epoch 00010: saving model to training_1\\cp.ckpt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x160213ef9a0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model during and afer training. Usual in case your computer crashes halfway thorugh\n",
    "checkpoint_path = \"training_1/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create a callback that saves the model's weights\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)\n",
    "\n",
    "# Train the model with the new callback\n",
    "model.fit(train_images, \n",
    "        train_labels,  \n",
    "        epochs=10,\n",
    "        validation_data=(test_images, test_labels),\n",
    "        callbacks=[cp_callback])  # Pass callback to training\n",
    "\n",
    "# This may generate warnings related to saving the state of the optimizer.\n",
    "# These warnings (and similar warnings throughout this notebook)\n",
    "# are in place to discourage outdated usage, and can be ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "headed-mozambique",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C has no label.\n",
      " Volume Serial Number is DAEB-91B6\n",
      "\n",
      " Directory of C:\\Users\\antho\\Desktop\\programming\\machine_learning_learning\\tutorials\\08_saving_loading\\training_1\n",
      "\n",
      "02/09/2021  07:38 AM    <DIR>          .\n",
      "02/09/2021  07:38 AM    <DIR>          ..\n",
      "02/09/2021  07:38 AM                71 checkpoint\n",
      "02/09/2021  07:38 AM         4,886,673 cp.ckpt.data-00000-of-00001\n",
      "02/09/2021  07:38 AM             1,222 cp.ckpt.index\n",
      "               3 File(s)      4,887,966 bytes\n",
      "               2 Dir(s)  227,544,252,416 bytes free\n"
     ]
    }
   ],
   "source": [
    "ls {checkpoint_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vocational-grass",
   "metadata": {},
   "source": [
    "IMPORTANT - when loading the model you have to create a model first. All you do when saving the model \n",
    "is save the weights. So, let's load it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "herbal-calvin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 - 0s - loss: 2.4033 - sparse_categorical_accuracy: 0.0850\n",
      "Untrained model, accuracy:  8.50%\n"
     ]
    }
   ],
   "source": [
    "# Create a basic model instance\n",
    "model = create_model()\n",
    "\n",
    "# Evaluate the untrained model\n",
    "loss, acc = model.evaluate(test_images, test_labels, verbose=2)\n",
    "print(\"Untrained model, accuracy: {:5.2f}%\".format(100 * acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "south-seventh",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 - 0s - loss: 0.4258 - sparse_categorical_accuracy: 0.8660\n",
      "Restored model, accuracy: 86.60%\n"
     ]
    }
   ],
   "source": [
    "# Loads the weights\n",
    "model.load_weights(checkpoint_path)\n",
    "\n",
    "# Re-evaluate the model\n",
    "loss, acc = model.evaluate(test_images, test_labels, verbose=2)\n",
    "print(\"Restored model, accuracy: {:5.2f}%\".format(100 * acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "natural-table",
   "metadata": {},
   "source": [
    "But wait, there's more. \n",
    "\n",
    "We and save with unique file names, for exmaple, use the epoch in the name. We'll be saviing ever 5 epoch in this instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "structured-earthquake",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00005: saving model to training_2\\cp-0005.ckpt\n",
      "\n",
      "Epoch 00010: saving model to training_2\\cp-0010.ckpt\n",
      "\n",
      "Epoch 00015: saving model to training_2\\cp-0015.ckpt\n",
      "\n",
      "Epoch 00020: saving model to training_2\\cp-0020.ckpt\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "\n",
      "Epoch 00025: saving model to training_2\\cp-0025.ckpt\n",
      "\n",
      "Epoch 00030: saving model to training_2\\cp-0030.ckpt\n",
      "\n",
      "Epoch 00035: saving model to training_2\\cp-0035.ckpt\n",
      "\n",
      "Epoch 00040: saving model to training_2\\cp-0040.ckpt\n",
      "\n",
      "Epoch 00045: saving model to training_2\\cp-0045.ckpt\n",
      "\n",
      "Epoch 00050: saving model to training_2\\cp-0050.ckpt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1614b5c6cd0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Include the epoch in the file name (uses `str.format`)\n",
    "checkpoint_path = \"training_2/cp-{epoch:04d}.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# Create a callback that saves the model's weights every 5 epochs\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_path, \n",
    "    verbose=1, \n",
    "    save_weights_only=True,\n",
    "    save_freq=5*batch_size)\n",
    "\n",
    "# Create a new model instance\n",
    "model = create_model()\n",
    "\n",
    "# Save the weights using the `checkpoint_path` format\n",
    "model.save_weights(checkpoint_path.format(epoch=0))\n",
    "\n",
    "# Train the model with the new callback\n",
    "model.fit(train_images, \n",
    "          train_labels,\n",
    "          epochs=50, \n",
    "          callbacks=[cp_callback],\n",
    "          validation_data=(test_images, test_labels),\n",
    "          verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "educational-priority",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C has no label.\n",
      " Volume Serial Number is DAEB-91B6\n",
      "\n",
      " Directory of C:\\Users\\antho\\Desktop\\programming\\machine_learning_learning\\tutorials\\08_saving_loading\\training_2\n",
      "\n",
      "02/09/2021  07:42 AM    <DIR>          .\n",
      "02/09/2021  07:42 AM    <DIR>          ..\n",
      "02/09/2021  07:42 AM                81 checkpoint\n",
      "02/09/2021  07:42 AM         1,628,726 cp-0000.ckpt.data-00000-of-00001\n",
      "02/09/2021  07:42 AM               402 cp-0000.ckpt.index\n",
      "02/09/2021  07:42 AM         4,886,685 cp-0005.ckpt.data-00000-of-00001\n",
      "02/09/2021  07:42 AM             1,222 cp-0005.ckpt.index\n",
      "02/09/2021  07:42 AM         4,886,685 cp-0010.ckpt.data-00000-of-00001\n",
      "02/09/2021  07:42 AM             1,222 cp-0010.ckpt.index\n",
      "02/09/2021  07:42 AM         4,886,685 cp-0015.ckpt.data-00000-of-00001\n",
      "02/09/2021  07:42 AM             1,222 cp-0015.ckpt.index\n",
      "02/09/2021  07:42 AM         4,886,685 cp-0020.ckpt.data-00000-of-00001\n",
      "02/09/2021  07:42 AM             1,222 cp-0020.ckpt.index\n",
      "02/09/2021  07:42 AM         4,886,685 cp-0025.ckpt.data-00000-of-00001\n",
      "02/09/2021  07:42 AM             1,222 cp-0025.ckpt.index\n",
      "02/09/2021  07:42 AM         4,886,685 cp-0030.ckpt.data-00000-of-00001\n",
      "02/09/2021  07:42 AM             1,222 cp-0030.ckpt.index\n",
      "02/09/2021  07:42 AM         4,886,685 cp-0035.ckpt.data-00000-of-00001\n",
      "02/09/2021  07:42 AM             1,222 cp-0035.ckpt.index\n",
      "02/09/2021  07:42 AM         4,886,685 cp-0040.ckpt.data-00000-of-00001\n",
      "02/09/2021  07:42 AM             1,222 cp-0040.ckpt.index\n",
      "02/09/2021  07:42 AM         4,886,685 cp-0045.ckpt.data-00000-of-00001\n",
      "02/09/2021  07:42 AM             1,222 cp-0045.ckpt.index\n",
      "02/09/2021  07:42 AM         4,886,685 cp-0050.ckpt.data-00000-of-00001\n",
      "02/09/2021  07:42 AM             1,222 cp-0050.ckpt.index\n",
      "              23 File(s)     50,508,279 bytes\n",
      "               2 Dir(s)  227,495,059,456 bytes free\n"
     ]
    }
   ],
   "source": [
    "ls {checkpoint_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "korean-enhancement",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at all them files!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "correct-earthquake",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'training_2\\\\cp-0050.ckpt'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Handy method to only get the latest\n",
    "latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "terminal-unknown",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 - 0s - loss: 0.4938 - sparse_categorical_accuracy: 0.8740\n",
      "Restored model, accuracy: 87.40%\n"
     ]
    }
   ],
   "source": [
    "# Test out the latest\n",
    "# Create a new model instance\n",
    "model = create_model()\n",
    "\n",
    "# Load the previously saved weights\n",
    "model.load_weights(latest)\n",
    "\n",
    "# Re-evaluate the model\n",
    "loss, acc = model.evaluate(test_images, test_labels, verbose=2)\n",
    "print(\"Restored model, accuracy: {:5.2f}%\".format(100 * acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amazing-mapping",
   "metadata": {},
   "source": [
    "### Manually Saving the Weights\n",
    "\n",
    "We can also manually save the model weights as shown here. All this does is save the weights to a given file. Nothing too fancy here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "qualified-disability",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 - 0s - loss: 0.4938 - sparse_categorical_accuracy: 0.8740\n",
      "Restored model, accuracy: 87.40%\n"
     ]
    }
   ],
   "source": [
    "# Save the weights\n",
    "model.save_weights('./checkpoints/my_checkpoint')\n",
    "\n",
    "# Create a new model instance\n",
    "model = create_model()\n",
    "\n",
    "# Restore the weights\n",
    "model.load_weights('./checkpoints/my_checkpoint')\n",
    "\n",
    "# Evaluate the model\n",
    "loss, acc = model.evaluate(test_images, test_labels, verbose=2)\n",
    "print(\"Restored model, accuracy: {:5.2f}%\".format(100 * acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arbitrary-decimal",
   "metadata": {},
   "source": [
    "### Save the Whole Thing\n",
    "Instead of having to create the exact model before we load the weights, we could just load the entire model from the file along with the weights. That would be nice if we wanted to share our model without having to tell the person exactly what archetecture we used. So, let's do that. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "binary-mustang",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 1.6214 - sparse_categorical_accuracy: 0.4781\n",
      "Epoch 2/5\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4648 - sparse_categorical_accuracy: 0.8532\n",
      "Epoch 3/5\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3312 - sparse_categorical_accuracy: 0.9058\n",
      "Epoch 4/5\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2099 - sparse_categorical_accuracy: 0.9490\n",
      "Epoch 5/5\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.1434 - sparse_categorical_accuracy: 0.9658\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "INFO:tensorflow:Assets written to: saved_model/my_model\\assets\n"
     ]
    }
   ],
   "source": [
    "# Create and train a new model instance.\n",
    "model = create_model()\n",
    "model.fit(train_images, train_labels, epochs=5)\n",
    "\n",
    "# Save the entire model as a SavedModel.\n",
    "!mkdir -p saved_model\n",
    "model.save('saved_model/my_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "legitimate-quebec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['my_model']\n",
      "['assets', 'saved_model.pb', 'variables']\n"
     ]
    }
   ],
   "source": [
    "# Let's see the damage\n",
    "print(os.listdir('./saved_model/'))\n",
    "\n",
    "print(os.listdir('./saved_model/my_model/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "living-slovakia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['assets', 'saved_model.pb', 'variables']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('./saved_model/my_model/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cellular-barcelona",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_12 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Load that model back in as it's own. \n",
    "new_model = tf.keras.models.load_model('saved_model/my_model')\n",
    "\n",
    "# Check its architecture\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "atlantic-oxford",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hey, that looks like the model that we started with!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "covered-swedish",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 - 0s - loss: 0.4283 - sparse_categorical_accuracy: 0.8610\n",
      "Restored model, accuracy: 86.10%\n",
      "(1000, 10)\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the restored model\n",
    "loss, acc = new_model.evaluate(test_images, test_labels, verbose=2)\n",
    "print('Restored model, accuracy: {:5.2f}%'.format(100 * acc))\n",
    "\n",
    "print(new_model.predict(test_images).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "still-decision",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 1.6489 - sparse_categorical_accuracy: 0.4868\n",
      "Epoch 2/5\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4104 - sparse_categorical_accuracy: 0.8814\n",
      "Epoch 3/5\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3392 - sparse_categorical_accuracy: 0.8996\n",
      "Epoch 4/5\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2057 - sparse_categorical_accuracy: 0.9500\n",
      "Epoch 5/5\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.1648 - sparse_categorical_accuracy: 0.9656\n"
     ]
    }
   ],
   "source": [
    "# HDF5 file format - no idea. \n",
    "# Create and train a new model instance.\n",
    "model = create_model()\n",
    "model.fit(train_images, train_labels, epochs=5)\n",
    "\n",
    "# Save the entire model to a HDF5 file.\n",
    "# The '.h5' extension indicates that the model should be saved to HDF5.\n",
    "model.save('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "elementary-mercy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_14 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Recreate the exact same model, including its weights and the optimizer\n",
    "new_model = tf.keras.models.load_model('my_model.h5')\n",
    "\n",
    "# Show the model architecture\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "internal-monitoring",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 - 0s - loss: 0.4386 - sparse_categorical_accuracy: 0.8570\n",
      "Restored model, accuracy: 85.70%\n"
     ]
    }
   ],
   "source": [
    "loss, acc = new_model.evaluate(test_images, test_labels, verbose=2)\n",
    "print('Restored model, accuracy: {:5.2f}%'.format(100 * acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tested-aggregate",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "Pretty basic, but very important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "described-anthony",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
